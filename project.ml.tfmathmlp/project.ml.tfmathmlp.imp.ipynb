{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical Representation of a Perceptron Layer\n",
    "## (with example in TensorFlow)\n",
    "---\n",
    "\n",
    "## Application in TensorFlow\n",
    "\n",
    "Task: classify handwritten digits\n",
    "\n",
    "Input: 1797 images of handwritten digits, 8x8 pixels each\n",
    "\n",
    "Output: 10 classes, [0, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits ()\n",
    "digits.keys ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot some random images with handwritten images\n",
    "rnd_idx = np.random.choice (digits['images'].shape[0], 10, replace = False)\n",
    "\n",
    "fig, axs = plt.subplots (1, len (rnd_idx))\n",
    "\n",
    "for i in range (len (rnd_idx)):\n",
    "    axs[i].imshow (digits['images'][rnd_idx[i], :], cmap = 'gray')\n",
    "    axs[i].set_title (digits['target'][rnd_idx[i]])\n",
    "    axs[i].axis ('off')\n",
    "\n",
    "fig.set_size_inches (10, 2)\n",
    "plt.tight_layout ()\n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset instances:\n",
      "   m = 1797 \n",
      "   features = (8, 8) \n",
      "   feature range = [0.0, 16.0] \n",
      "   feature data type = float64\n",
      "dataset targets: \n",
      "   y = [0 1 2 3 4 5 6 7 8 9] \n",
      "   targets data type = int32\n",
      "distribution of instances per target:\n",
      "   0 178    9.91 %   9.91 %\n",
      "   1 182   10.13 %  20.04 %\n",
      "   2 177    9.85 %  29.89 %\n",
      "   3 183   10.18 %  40.07 %\n",
      "   4 181   10.07 %  50.14 %\n",
      "   5 182   10.13 %  60.27 %\n",
      "   6 181   10.07 %  70.34 %\n",
      "   7 179    9.96 %   80.3 %\n",
      "   8 174    9.68 %  89.98 %\n",
      "   9 180   10.02 %  100.0 %\n"
     ]
    }
   ],
   "source": [
    "# insights of the dataset\n",
    "print ('dataset instances:\\n',\n",
    "       '  m =', digits['images'].shape[0], '\\n',\n",
    "       '  features =', digits['images'].shape[1:], '\\n',\n",
    "       '  feature range = [{}, {}]'.format (digits['images'].min (), digits['images'].max ()), '\\n',\n",
    "       '  feature data type =', digits['images'].dtype)\n",
    "print ('dataset targets:', '\\n',\n",
    "       '  y =', digits['target_names'], '\\n',\n",
    "       '  targets data type =', digits['target_names'].dtype)\n",
    "\n",
    "print ('distribution of instances per target:')\n",
    "cum_percent_of_instances = 0\n",
    "for i in range (digits['target_names'].shape[0]):\n",
    "    n_instances_per_label = len (np.where (digits['target'].reshape (-1, 1) == i)[0])\n",
    "    percent_of_instances = np.round_ (100*n_instances_per_label / digits['images'].shape[0], 2)\n",
    "    cum_percent_of_instances += percent_of_instances\n",
    "    print ('  {:2} {:<4} {:>6} % {:>6} %'.format (i, n_instances_per_label, percent_of_instances, np.round_ (cum_percent_of_instances, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale dataset to [0, 1] - min-max scaling\n",
    "digits_scaled = digits['data'].astype ('f4') / np.max (digits['data'])\n",
    "np.min (digits_scaled), np.max (digits_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: (1153, 64) (1153,) 64.16 %\n",
      "val set: (289, 64) (289,) 16.08 %\n",
      "test set: (355, 64) (355,) 19.76 %\n"
     ]
    }
   ],
   "source": [
    "# split dataset into train, validation, test set\n",
    "\n",
    "# take out 20% of each target class for test\n",
    "data = []\n",
    "idx_test = []\n",
    "for i in range (digits['target_names'].shape[0]):\n",
    "    i_idx = np.where (digits['target'].reshape (-1, 1) == i)[0]\n",
    "    rnd_i_idx = np.random.choice (i_idx, int (np.floor (len (i_idx)*0.2)), replace = False)\n",
    "    digits_Xy = np.concatenate ((digits_scaled[rnd_i_idx], digits['target'][rnd_i_idx].reshape (-1, 1)), axis = 1)\n",
    "    data.append (digits_Xy)\n",
    "    idx_test.append (rnd_i_idx)\n",
    "\n",
    "digits_Xy_test = np.vstack (data)\n",
    "\n",
    "digits_X_test = digits_Xy_test[:, :64]\n",
    "digits_y_test = digits_Xy_test[:, 64].astype ('i4')\n",
    "\n",
    "# delete the test data from dataset\n",
    "mask = np.ones (digits_scaled.shape[0], dtype = bool)\n",
    "mask[np.hstack (idx_test)] = False\n",
    "digits_X = digits_scaled[mask]\n",
    "digits_y = digits['target'][mask]\n",
    "\n",
    "# split remaining dataset into train and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits_X_train, digits_X_val, digits_y_train, digits_y_val = train_test_split (digits_X, digits_y, test_size = 0.2, shuffle = True, random_state = 42)\n",
    "\n",
    "\n",
    "print ('train set:', digits_X_train.shape, digits_y_train.shape, np.round_ (100*digits_X_train.shape[0] / digits_scaled.shape[0], 2), '%')\n",
    "print ('val set:', digits_X_val.shape, digits_y_val.shape, np.round_ (100*digits_X_val.shape[0] / digits_scaled.shape[0], 2), '%')\n",
    "print ('test set:', digits_X_test.shape, digits_y_test.shape, np.round_ (100*digits_X_test.shape[0] / digits_scaled.shape[0], 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer\n",
    "def nn_layer (inputs, units, activation = None):\n",
    "        \n",
    "    # X, shape (k, n)\n",
    "    X = inputs\n",
    "    \n",
    "    # W, shape (n, u)\n",
    "    r = 2 / np.sqrt (units)\n",
    "    w_init = tf.random_uniform (shape = [int (X.get_shape ()[1]), units], minval = -1.*r, maxval = 1.*r)\n",
    "    W = tf.Variable (\n",
    "        initial_value = w_init,\n",
    "        name = 'weights'\n",
    "    )\n",
    "    \n",
    "    # b, shape (u, 1)\n",
    "    b = tf.Variable (\n",
    "        initial_value = tf.zeros (shape = [units]),\n",
    "        name = 'bias'\n",
    "    )\n",
    "    \n",
    "    # Z = X * W + b with shape (k, u)\n",
    "    Z = tf.matmul (X, W) + b\n",
    "    \n",
    "    # H = activation (Z)\n",
    "    if activation:\n",
    "        return activation (Z)\n",
    "    else:\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construction phase\n",
    "n_inputs = 8*8\n",
    "n_hidden1 = 256\n",
    "n_hidden2 = 128\n",
    "n_outputs = 10\n",
    "\n",
    "\n",
    "tf.reset_default_graph ()\n",
    "\n",
    "X = tf.placeholder (\n",
    "    dtype = tf.float32,\n",
    "    shape = (None, n_inputs),\n",
    "    name = 'X'\n",
    ")\n",
    "y = tf.placeholder (\n",
    "    dtype = tf.int32,\n",
    "    shape = (None),\n",
    "    name = 'y'\n",
    ")\n",
    "\n",
    "fc1 = nn_layer (\n",
    "    inputs = X,\n",
    "    units = n_hidden1,\n",
    "    activation = tf.nn.relu\n",
    ")\n",
    "fc2 = nn_layer (\n",
    "    inputs = fc1,\n",
    "    units = n_hidden2,\n",
    "    activation = tf.nn.relu\n",
    ")\n",
    "logits = nn_layer (\n",
    "    inputs = fc2,\n",
    "    units = n_outputs,\n",
    "    activation = None\n",
    ")\n",
    "\n",
    "with tf.name_scope ('loss'): # cost function\n",
    "    # sparse_softmax_cross_entropy_with_logits includes softmax activation function\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits (\n",
    "        labels = y,\n",
    "        logits = logits\n",
    "    )\n",
    "    loss = tf.reduce_mean (xentropy, name = 'loss')\n",
    "\n",
    "LR = 0.01\n",
    "with tf.name_scope ('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer (learning_rate = LR)\n",
    "    training_op = optimizer.minimize (loss)\n",
    "    \n",
    "with tf.name_scope ('eval'):\n",
    "    correct = tf.nn.in_top_k (\n",
    "        predictions = logits,\n",
    "        targets = y,\n",
    "        k = 1\n",
    "    )\n",
    "    accuracy = tf.reduce_mean (tf.cast (correct, tf.float32))\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer ()\n",
    "saver = tf.train.Saver ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 , train acc: 0.9230769 , val acc: 0.816609\n",
      "2 , train acc: 1.0 , val acc: 0.9134948\n",
      "3 , train acc: 1.0 , val acc: 0.9446367\n",
      "4 , train acc: 1.0 , val acc: 0.9550173\n",
      "5 , train acc: 1.0 , val acc: 0.9584775\n",
      "6 , train acc: 1.0 , val acc: 0.9584775\n",
      "7 , train acc: 1.0 , val acc: 0.9584775\n",
      "8 , train acc: 1.0 , val acc: 0.9688581\n",
      "9 , train acc: 1.0 , val acc: 0.9688581\n",
      "10 , train acc: 1.0 , val acc: 0.97231835\n",
      "11 , train acc: 1.0 , val acc: 0.9688581\n",
      "12 , train acc: 1.0 , val acc: 0.9688581\n",
      "13 , train acc: 1.0 , val acc: 0.9688581\n",
      "14 , train acc: 1.0 , val acc: 0.9688581\n",
      "15 , train acc: 1.0 , val acc: 0.9653979\n",
      "16 , train acc: 1.0 , val acc: 0.9653979\n",
      "17 , train acc: 1.0 , val acc: 0.9653979\n",
      "18 , train acc: 1.0 , val acc: 0.9653979\n",
      "19 , train acc: 1.0 , val acc: 0.9653979\n",
      "20 , train acc: 1.0 , val acc: 0.9653979\n"
     ]
    }
   ],
   "source": [
    "# execution phase\n",
    "\n",
    "N_EPOCHS = 20\n",
    "BATCH_SIZE = 20\n",
    "n_batches = int (np.ceil (digits_X_train.shape[0] / BATCH_SIZE))\n",
    "\n",
    "with tf.Session () as sess:\n",
    "    init.run ()\n",
    "    \n",
    "    for epoch in range (1, N_EPOCHS+1):\n",
    "        \n",
    "        for it in range (n_batches):\n",
    "            \n",
    "            feed_dict = {\n",
    "                X : digits_X_train[it*BATCH_SIZE:(it+1)*BATCH_SIZE, :],\n",
    "                y : digits_y_train[it*BATCH_SIZE:(it+1)*BATCH_SIZE]\n",
    "            }\n",
    "            \n",
    "            sess.run (training_op, feed_dict = feed_dict)\n",
    "        \n",
    "        acc_train = accuracy.eval (feed_dict = feed_dict)\n",
    "        acc_val = accuracy.eval (feed_dict = {X : digits_X_val, y : digits_y_val})\n",
    "        \n",
    "        print (epoch, ', train acc:', acc_train, ', val acc:', acc_val)\n",
    "    \n",
    "    save_path = saver.save (sess, './digits_final.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./digits_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "with tf.Session () as sess:\n",
    "    saver.restore (sess, save_path)\n",
    "    \n",
    "    Z = logits.eval (feed_dict = {X : digits_X_test})\n",
    "    y_pred_distr = tf.nn.softmax (Z).eval ()\n",
    "    y_pred = np.argmax (y_pred_distr, axis = 1)\n",
    "    acc_test = accuracy.eval (feed_dict = {X : digits_X_test, y : digits_y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9661972"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
